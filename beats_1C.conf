# Logstash pipeline для парсинга ТЖ (Технологического журнала) 1С
# Beats -> Logstash -> Elasticsearch pipeline.

input {
  beats {
    port => 5044
    include_codec_tag => false
  }
}

filter {
  if "already_parsed" not in [tags] {
# Выделяем минуты, секунды, миллисекунды, длительность, тип вызова, уровень ТЖ. Остальное - в payload.
    grok {
      match => { "message" => "%{MINUTE:tj_minute:int}:%{SECOND:tj_second:int}.%{WORD:tj_millisecond}-%{INT:tj.duration:int},%{WORD:tj.type},%{INT:tj.level:int},%{GREEDYDATA:payload}" }
    }
# Выделяем PID-процесса, оставившего лог и год, день, месяц, час из имени файла
    grok {
      match => {"source" => "%{GREEDYDATA}_%{INT:pid:int}\\(?<tj_year>\d{2})%{MONTHNUM2:tj_month:int}%{MONTHDAY:tj_day:int}%{HOUR:tj_hour:int}.log"}
    }
# Преобразовываем в поле tj_timestamp для проставления даты
    mutate {
      gsub => ["tj_millisecond", "[0-9]{3}$",""]
      add_field => {"tj.timestamp" => "%{tj_year}-%{tj_month}-%{tj_day} %{tj_hour}:%{tj_minute}:%{tj_second}.%{tj_millisecond}"}
      remove_field => ["tj_year", "tj_month", "tj_day", "tj_hour", "tj_minute", "tj_second", "tj_millisecond"]
    }
# Приводим tj_timestamp к дате события
    date {
      match => ["tj.timestamp", "yy-MM-dd HH:mm:ss.SSS"]
      timezone => "Europe/Moscow"
    }
# Заменим следующие подряд друг за другом двойные кавычки на двойные. Наличие двух следующих подряд одинарных кавычек мешает разбору сложных выражений.
    mutate {
      gsub => ["payload","''", "\""]
    }
# Удалим сложное многострочное высказывания типа Sql, Context, Descr
## SQL
    grok {
      match => { "payload" => "%{GREEDYDATA:temp_payload},Sql=%{QS:Sql}%{GREEDYDATA:temp_payload_ending}" }
      break_on_match => false
      tag_on_failure => []
    }
    if ([temp_payload_ending]) {
      mutate {
        add_field => { "temp_payload" => "%{temp_payload}%{temp_payload_ending}" }
      }
    }
    if ([temp_payload]) {
      mutate {
        rename => { "temp_payload" => "payload" }
        remove_field => ["temp_payload_ending"]
      }
    }
## CONTEXT
    grok {
      match => { "payload" => "%{GREEDYDATA:temp_payload},Context=%{QS:Context}%{GREEDYDATA:temp_payload_ending}" }
      break_on_match => false
      tag_on_failure => []
    }
    if ([temp_payload_ending]) {
      mutate {
        add_field => { "temp_payload" => "%{temp_payload}%{temp_payload_ending}" }
      }
    }
    if ([temp_payload]) {
      mutate {
        rename => { "temp_payload" => "payload" }
	remove_field => ["temp_payload_ending"]
      }
    }
## DESCRIPTION
    grok {
      match => { "payload" => "%{GREEDYDATA:temp_payload},Descr=%{QS:Descr}%{GREEDYDATA:temp_payload_ending}" }
      break_on_match => false
      tag_on_failure => []
    }
    if ([temp_payload_ending]) {
      mutate {
        add_field => { "temp_payload" => "%{temp_payload}%{temp_payload_ending}" }
      }
    }
    if ([temp_payload]) {
      mutate {
        rename => { "temp_payload" => "payload" }
        remove_field => ["temp_payload_ending"]
      }
    }

# Преобразуем payload в key-value
    kv {
      source => "payload" 
      field_split_pattern => ","
      value_split_pattern => "="
      include_brackets => "false"
      whitespace => strict
      recursive => "false"
      allow_duplicate_values => false
    }
# Удалим поля, образовавшие timestamp и payload - они нам больше не нужны
    mutate {
      remove_field => ["tj_year", "tj_month", "tj_day", "tj_hour", "tj_minute", "tj_second", "tj_millisecond", "tj_timestamp", "message"]
    }
  # Если в процессе выполнения вызова сервера выводились события в технологический журнал, 
  # то после возврата управления клиенту он отправляет серверу свой контекcт отдельным вызовом, и сервер 
  # выводит этот контекст отдельным событием Context. В этом случае контекст не может быть добавлен 
  # в события в виде свойств, посколько к моменту получения контекста события уже завершены и выведены в файл журнала.
  # Событие context будет следующим за событием call с таким же значением свойста t:clientID. 
  # Если следующим за событием call с данным значеннием t:clientID записано кокое-нибудь другое событие, 
  # то это значит, что события context не будет.
#    if ([tj_type] == "CALL") {
#      aggregate {
#        task_id => "%{t:clientID}"
#        map_action => "update"
#        code => "
#          generated_event = LogStash::Event.new(map['event']);
#          generated_event.tag('already_parsed');
#	  generated_event.tag('aggregate_cancel_by_next_call');
#          new_event_block.call(generated_event);
#          event.tag('create_new_map');
#          map['event'] = event.to_hash;
#          event.cancel;
#        "
#      }
#    }
#    if ([tj_type] == "CALL") {
#      aggregate {
#        task_id => "%{t:clientID}"
#        map_action => "create"
#        code => "
#          event.tag('create_aggregation');
#          map['event'] = event.to_hash;
#          event.cancel;
#        "
#        timeout => 300 # 5 minutes timeout
#        timeout_tags => ['_aggregatetimeout']
#        push_map_as_event_on_timeout => true
#      }
#    }
#    if ([tj_type] == "Context") {
#      aggregate {
#        task_id => "%{t:clientID}"
#        map_action => "update"
#        end_of_task => true
#        code => "
#          generated_event = LogStash::Event.new(map['event']);
#          generated_event.tag('context_added');
#          generated_event.tag('already_parsed');
#          generated_event.set('Context', event.get('Context'));
#          new_event_block.call(generated_event);
#          event.cancel;
#        "
#    }
#  }
#}
#if "_aggregatetimeout" in [tags] {
#    ruby {
#      code => "
#        generated_event = LogStash::Event.new(event.get('event'));
#        generated_event.tag('already_parsed');
#        generated_event.tag('aggregate_cancel_by_timeout');
#        new_event_block.call(generated_event);
#        event.cancel;
#      "
#    }
}
mutate {
  remove_tag => ['already_parsed']
}
# Приводим к числовому типу известные поля, если таковые имеются
  if [MemoryPeak] {
    mutate {
     convert => { "MemoryPeak" => "integer" }
    }
  }
  if [OutBytes] {
    mutate {
     convert => { "OutBytes" => "integer" }
    }
  }
  if [InBytes] {
    mutate {
     convert => { "InBytes" => "integer" }
    }
  }
  if [Memory] {
    mutate {
     convert => { "Memory" => "integer" }
    }
  }
  if [OSThread] {
    mutate {
     convert => { "OSThread" => "integer" }
    }
  }
  if [dbpid] {
    mutate {
     convert => { "dbpid" => "integer" }
    }
  }
  if [Rows] {
    mutate {
     convert => { "Rows" => "integer" }
    }
  }
  if [RowsAffected] {
    mutate {
     convert => { "RowsAffected" => "integer" }
    }
  }
  if [t:clientID] {
    mutate {
     convert => { "t:clientID" => "integer" }
    }
  }
  if [t:connectID] {
    mutate {
     convert => { "t:connectID" => "integer" }
    }
  }
# В SessionID хранятся идентификатор и клиентского вызова и серверного!!!
#  if [SessionID] {
#    mutate {
#     convert => { "SessionID" => "integer" }
#    }
#  }
  if [Trans] {
    mutate {
     convert => { "Trans" => "integer" }
    }
  }
  if [callWait] {
    mutate {
     convert => { "CallWait" => "integer" }
    }
  }
  if [CpuTime] {
    mutate {
     convert => { "CpuTime" => "integer" }
    }
  }

# Если существует поле Descr - его тоже можно попробовать преобразовать в key-value
# ОТЛОЖЕНО. ПРИЧИНА: плохо разбирается ключ descr - пробельные символы в нем для программы выглядят как разделитель пар.
#  if [Descr] {
#    kv {
#      source => "Descr"
#      prefix => "Descr_"
#      field_split => " "
#      value_split => "="
#      include_brackets => true
#    }
#  }
# Фоновые задания, запущенные пользователем, отличаются от запущенных регламентом наличием двух SessionID - пользователя и серверного процесса. Помечаем такие. 
  if ("(" in [SessionID]) {
    mutate {
      add_tag => ["is_users_background_process"]
    }
  }
# Разделим те параметры, которые известно, что можно разделить
  if ("," in [p:processName]) {
    mutate {
     split => { "p:processName" => "," }
    }
  }
}
output {
  elasticsearch {
    hosts => ["http://localhost:9200"]
    index => "1c-techincal-journal-%{+yyyy-MM-dd}"
    #user => "elastic"
    #password => "changeme"
  }
}
